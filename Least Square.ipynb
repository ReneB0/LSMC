{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'login.microsoftonline.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'login.microsoftonline.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local browser window will be open for you to sign in. CTRL+C to cancel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'inet-proxy-a.adns.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import msal #pip install msal in anaconda\n",
    "import logging\n",
    "import requests #pip install requests_negotiate_sspi\n",
    "import json\n",
    "\n",
    "\n",
    "class SpecialSession(requests.Session):\n",
    "    def request(self, method, url, *args, **kwargs):\n",
    "        if 'oauth2/v2.0/token' in url:\n",
    "            kwargs['proxies'] = {\n",
    "                'https': 'http://inet-proxy-a.adns.ubs.net:8085',\n",
    "                'http': 'http://inet-proxy-a.adns.ubs.net:8085'\n",
    "            }\n",
    "        return super().request(method, url, verify=False, *args, **kwargs)\n",
    "\n",
    "def get_token():\n",
    "    scopevar = \"app://ubscloud.onmicrosoft.com/AT10200/PROD/Panservice/OData.Read.All\"\n",
    "    clietnid = \"42f45e42-33c4-4be1-a028-cf0bb6b3b248\"\n",
    "\n",
    "    session = SpecialSession()\n",
    "    scope = [scopevar]\n",
    "    # Create a preferably long-lived app instance which maintains a token cache.\n",
    "    app = msal.PublicClientApplication(\n",
    "        clietnid,\n",
    "        authority=\"https://login.microsoftonline.com/fb6ea403-7cf1-4905-810a-fe5547e98204\",\n",
    "        # token_cache=...  # Default cache is in memory only.\n",
    "        # You can learn how to use SerializableTokenCache from\n",
    "        # https://msal-python.readthedocs.io/en/latest/#msal.SerializableTokenCache\n",
    "        http_client=session\n",
    "    )\n",
    "    # The pattern to acquire a token looks like this.\n",
    "    result = None\n",
    "    # Firstly, check the cache to see if this end user has signed in before\n",
    "    accounts = app.get_accounts(\"rene.brupbacher@ubs.com\")\n",
    "    if accounts:\n",
    "        logging.info(\"Account(s) exists in cache, probably with token too. Let's try.\")\n",
    "        print(\"Account(s) already signed in:\")\n",
    "        for a in accounts:\n",
    "            print(a[\"username\"])\n",
    "        chosen = accounts[0]  # Assuming the end user chose this one to proceed\n",
    "        print(\"Proceed with account: %s\" % chosen[\"username\"])\n",
    "        # Now let's try to find a token in cache for this account\n",
    "        result = app.acquire_token(scope, account=chosen)\n",
    "    if not result:\n",
    "        logging.info(\"No suitable token exists in cache. Let's get a new one from AAD.\")\n",
    "        print(\"A local browser window will be open for you to sign in. CTRL+C to cancel.\")\n",
    "        result = app.acquire_token_interactive(\n",
    "            scope\n",
    "        )\n",
    "    return result\n",
    "\n",
    "# region get token / print token\n",
    "token = get_token()\n",
    "access_token = str(token)\n",
    "\n",
    "# endregion\n",
    "my_headers = {'Authorization': \"Bearer {}\".format(token.get('access_token'))}\n",
    "\n",
    "url = 'https://saturn-pan.azure.ubs.net/odata'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import random\n",
    "import requests\n",
    "from requests_negotiate_sspi import HttpNegotiateAuth\n",
    "import xml.dom.minidom\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# for calculating mean_squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import openpyxl as xl\n",
    "\n",
    "\n",
    "#UAT\n",
    "#url = 'https://saturn-app.ubstest.net:5002/odata'\n",
    "\n",
    "#PROD\n",
    "#url = 'https://saturn-app.ubs.net:5002/odata'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import timeit\n",
    "#starttime = timeit.default_timer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Curr = datetime.today()\n",
    "tday = Curr.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "date_1yr = (Curr - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "date_1m = (Curr - timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCOUNT_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACCOUNT_ID\n",
       "0         103\n",
       "1         105\n",
       "2         186\n",
       "3         192"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get a/c Id in saturn for Europe '105' & Global '186' & Ichiysohi '192' & Nomura '186'\n",
    "r = requests.get(url+'/Accounts?$filter=GIM2_ACCOUNT_ID in (%2702093094%27,%2700572794%27,%2702299194%27,%2702237894%27) &$Select=ACCOUNT_ID', verify=False, headers=my_headers)\n",
    "#r = requests.get(url+'/Accounts', verify=False, headers=my_headers) \n",
    "json_content = r.json()\n",
    "\n",
    "instrument = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "instrDump = json.loads(instrument)\n",
    "account = pd.DataFrame(instrDump[\"value\"])\n",
    "account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tday = (Curr - timedelta(days=5)).strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "BD = today - BDay(1)\n",
    "BD = BD.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rr = requests.get(url + '/Holdings?$filter=ACCOUNT_ID in (103,105,186,192) and HOLDING_VALUE_DATE Ge ' + BD + ' and HOLDING_VALUE_DATE Le '+ BD +' and SOURCE_SYSTEM_ID eq %27DATAHUB%27 &$Select=ACCOUNT_ID,HOLDING_AMOUNT,INSTRUMENT_ID',  verify=False,headers=my_headers)\n",
    "#rr = requests.get(url + '/Holdings?$filter=ACCOUNT_ID in (105,186) and HOLDING_VALUE_DATE Ge ''2021-08-17'' and HOLDING_VALUE_DATE Le ''2021-08-17'' and SOURCE_SYSTEM_ID eq %27DATAHUB%27 &$Select=ACCOUNT_ID,HOLDING_VALUE_DATE,HOLDING_AMOUNT,INSTRUMENT_ID',  verify=False, auth=HttpNegotiateAuth()) \n",
    "#rr = requests.get(urlParam, verify=False, auth=HttpNegotiateAuth()) \n",
    " \n",
    "\n",
    "json_content = rr.json()\n",
    "\n",
    "instrument = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "instrDump = json.loads(instrument)\n",
    "pos = pd.DataFrame(instrDump[\"value\"])\n",
    "#instrument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pos.to_excel(\"Output_Saturn/positions1.xlsx\",index=False,na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = pos['INSTRUMENT_ID'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = pd.DataFrame(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "position1 = position.iloc[:250]\n",
    "position2 = position.iloc[250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1 = position1.INSTRUMENT_ID.str.cat(sep=',')\n",
    "pos2 = position2.INSTRUMENT_ID.str.cat(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#GETTING isin\n",
    "#rr = requests.get(url + '/Instruments?$filter=instrument_ID in (375740,390512) &$Select=instrument_ID,ISIN', verify=False, auth=HttpNegotiateAuth())\n",
    "#rr = requests.get(url + '/Instruments?$filter=instrument_ID in (375740,390512) &$Select=instrument_ID,ISIN', verify=False, auth=HttpNegotiateAuth())\n",
    "\n",
    "#rr = requests.get(url +'/Instruments?$filter=instrument_ID in (375740,390512) &$Select=instrument_ID,ISIN', verify=False, headers=my_headers)\n",
    "rr = requests.get(url +'/Instruments?$filter=instrument_ID in (' + pos1 + ') &$Select=instrument_ID,ISIN', verify=False, headers=my_headers)\n",
    "\n",
    "json_content = rr.json()\n",
    "\n",
    "\n",
    "\n",
    "instrument = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "instrDump = json.loads(instrument)\n",
    "isin1 = pd.DataFrame(instrDump[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rr = requests.get(url +'/Instruments?$filter=instrument_ID in (' + pos2 + ') &$Select=instrument_ID,ISIN', verify=False, headers=my_headers)\n",
    "\n",
    "json_content = rr.json()\n",
    "\n",
    "\n",
    "\n",
    "instrument = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "instrDump = json.loads(instrument)\n",
    "isin2 = pd.DataFrame(instrDump[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTRUMENT_ID</th>\n",
       "      <th>ISIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20015</td>\n",
       "      <td>XS0742395287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20074</td>\n",
       "      <td>US530715AG61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20168</td>\n",
       "      <td>XS1057356773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129541</td>\n",
       "      <td>XS1140296614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205844</td>\n",
       "      <td>XS1414094927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>824182</td>\n",
       "      <td>XS2296021798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>827053</td>\n",
       "      <td>XS2257580857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>850921</td>\n",
       "      <td>XS2284144339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>943525</td>\n",
       "      <td>XS2353011724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1021986</td>\n",
       "      <td>US75737FAC23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INSTRUMENT_ID          ISIN\n",
       "0            20015  XS0742395287\n",
       "1            20074  US530715AG61\n",
       "2            20168  XS1057356773\n",
       "3           129541  XS1140296614\n",
       "4           205844  XS1414094927\n",
       "..             ...           ...\n",
       "78          824182  XS2296021798\n",
       "80          827053  XS2257580857\n",
       "94          850921  XS2284144339\n",
       "116         943525  XS2353011724\n",
       "138        1021986  US75737FAC23\n",
       "\n",
       "[219 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isin = isin1.append(isin2)\n",
    "isin.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos['HOLDING'] = pos.groupby(['INSTRUMENT_ID'])['HOLDING_AMOUNT'].transform('sum')\n",
    "pos.drop_duplicates(subset=['INSTRUMENT_ID'], keep = 'first', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos.to_excel(\"Output_Saturn/positions2.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Holdings = pd.merge(pos,isin,how='left',on='INSTRUMENT_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdings['HOLDING'] = Holdings.groupby(['INSTRUMENT_ID'])['HOLDING_AMOUNT'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hlds = Holdings.drop_duplicates(subset=['INSTRUMENT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holdings.to_excel(\"Output_Saturn/Holdings.xlsx\",index=False,na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(dd):\n",
    "    flds = ''\n",
    "    for index, row in dd.iterrows():\n",
    "        if row['on/off']=='on':\n",
    "            if flds=='':\n",
    "                flds = str(row['field'])   \n",
    "            else:\n",
    "                flds += ',' + str(row['field'])                  \n",
    "                \n",
    "\n",
    "    return flds   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('field_selecter.xls')\n",
    "field_static = pd.read_excel(xls, 'static_PP')\n",
    "field_dynamic = pd.read_excel(xls, 'dynamic_PP')\n",
    "field_price = pd.read_excel(xls, 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fldsPRICE = concatenate(field_price)\n",
    "fldsINSTRTD = concatenate(field_dynamic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Instrument (Static Data)\n",
    "\n",
    "fldsINSTR = concatenate(field_static)\n",
    "\n",
    "\n",
    "r = requests.get(url+'/Instruments?$filter=INSTRUMENT_TP_IDS eq %27CONVERTIBLE_BOND%27 &$Select='+fldsINSTR, verify=False, headers=my_headers)\n",
    "#r = requests.get('https://saturn-pan.azure.ubs.net/odata/InstrumentTDs?$filter=VALUE_DATE Ge 2020-05-31 and VALUE_DATE Le 2022-01-21&$orderby=VALUE_DATE desc &$Select=ACCRUED_VALUE,CREDIT_SPREAD,INSTRUMENT_ID,DELTA,GAMMA,IMPLIED_VOLA,INPUT_VOLATILITY,PARITY,PREMIUM,THEORETICAL_PRICE,VALUE_DATE,VEGA', verify=False, headers=my_headers)\n",
    "json_content = r.json()\n",
    "\n",
    "instrument = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "instrDump = json.loads(instrument)\n",
    "instr = pd.DataFrame(instrDump[\"value\"])\n",
    "#instr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-13\n"
     ]
    }
   ],
   "source": [
    "#retrieves last update date\n",
    "\n",
    "import sqlite3 as sql\n",
    "conn = sql.connect('saturn.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT MAX(VALUE_DATE) AS maximum FROM 'cb'\")\n",
    "result=cursor.fetchall()\n",
    "value_date= result[0][0]\n",
    "print(value_date)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "end_date = date.today()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxDate = datetime.strptime(value_date,'%Y-%m-%d').date()\n",
    "\n",
    "DaysDelta = (end_date - MaxDate).days -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2023, 4, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = (end_date - timedelta(days=DaysDelta))\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'saturn-pan.azure.ubs.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-8de7092d8cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mevent_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfldsINSTRTD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfldsPRICE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDaysDelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mevent_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\jup385\\lib\\asyncio\\selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot close a running event loop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    }
   ],
   "source": [
    "       \n",
    "    \n",
    "resultList = []\n",
    "resultListPrice = []\n",
    "\n",
    "async def callRequest(url):\n",
    "\n",
    "    r = requests.get(url, verify=False, headers=my_headers)   \n",
    "    \n",
    "    json_content = r.json()\n",
    "    json_dump = json.dumps(json_content, indent = 4,sort_keys=False)\n",
    "    json_load = json.loads(json_dump)\n",
    "    res = pd.DataFrame(json_load[\"value\"])\n",
    "    \n",
    "\n",
    "    return res\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "async def main(urlINSTRTD, urlPRICE, DaysDelta):\n",
    "    \n",
    "    coroutines = []\n",
    "    coroutinesPrice = []\n",
    "    \n",
    "    #import datetime\n",
    "    #end_date = datetime.datetime(2020, 1, 1).date()\n",
    "    #start_date = datetime.datetime(2019, 1, 1).date()\n",
    "  \n",
    "    end_date = date.today()\n",
    "    start_date = (end_date - timedelta(days=DaysDelta))\n",
    "    delta = timedelta(days=10)\n",
    "    end_date_tmp = start_date + delta\n",
    "\n",
    "    while start_date <= end_date:\n",
    "\n",
    "        end_date_tmp = start_date + delta\n",
    "        url = 'https://saturn-pan.azure.ubs.net/odata/InstrumentTDs?$filter=VALUE_DATE ge ' + str(start_date) + ' and  VALUE_DATE lt ' + str(end_date_tmp) + '  &$Select=' + fldsINSTRTD\n",
    "\n",
    "        coroutines.append(callRequest(url))\n",
    "        start_date += delta\n",
    "        \n",
    "\n",
    "    \n",
    "    #end_date = datetime.datetime(2021, 12, 31).date()\n",
    "    #start_date = datetime.datetime(2021, 1, 1).date()\n",
    "  \n",
    "    end_date = date.today()\n",
    "    start_date = (end_date - timedelta(days=DaysDelta))\n",
    "    delta = timedelta(days=3)\n",
    "    end_date_tmp = start_date + delta \n",
    "        \n",
    "        \n",
    "    while start_date <= end_date:\n",
    "\n",
    "        end_date_tmp = start_date + delta\n",
    "        url = 'https://saturn-pan.azure.ubs.net/odata/Pricings?$filter=PRICE_DATE ge ' + str(start_date) + ' and  PRICE_DATE lt ' + str(end_date_tmp) + '  &$Select=' + fldsPRICE\n",
    "        coroutinesPrice.append(callRequest(url))\n",
    "        start_date += delta\n",
    "        \n",
    "     \n",
    "    \n",
    "    completed, pending = await asyncio.wait(coroutines)\n",
    "    for i in completed:\n",
    "        resultList.append(i.result())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    completed, pending = await asyncio.wait(coroutinesPrice)\n",
    "    for j in completed:\n",
    "        resultListPrice.append(j.result())    \n",
    "\n",
    "       \n",
    "        \n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    event_loop = asyncio.get_event_loop()\n",
    "    try:\n",
    "        event_loop.run_until_complete(main(fldsINSTRTD, fldsPRICE, DaysDelta))\n",
    "    finally:\n",
    "        event_loop.close()\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      INSTRUMENT_ID                 PRICE_DATE PRICE_CCY  PRICE_CLOSE\n",
       " 0            720926  2023-04-14T00:00:00+02:00       USD      75.0819\n",
       " 1            901014  2023-04-14T00:00:00+02:00       USD      73.4743\n",
       " 2            746588  2023-04-14T00:00:00+02:00       EUR     102.7500\n",
       " 3            799491  2023-04-14T00:00:00+02:00       EUR      46.5580\n",
       " 4            488301  2023-04-14T00:00:00+02:00       EUR      98.3470\n",
       " ...             ...                        ...       ...          ...\n",
       " 1894        1018411  2023-04-14T00:00:00+02:00       USD      96.3017\n",
       " 1895        1020937  2023-04-14T00:00:00+02:00       EUR      45.0280\n",
       " 1896        1020938  2023-04-14T00:00:00+02:00       AUD      95.0000\n",
       " 1897        1024040  2023-04-14T00:00:00+02:00       USD     105.1000\n",
       " 1898        1024367  2023-04-14T00:00:00+02:00       EUR      97.3150\n",
       " \n",
       " [1899 rows x 4 columns],\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: []]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultListPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     INSTRUMENT_ID  ACCRUED_VALUE  CREDIT_SPREAD      DELTA     GAMMA  \\\n",
       " 0           720926       1.043750         1200.0  10.392678  0.002066   \n",
       " 1           901014       0.000000          600.0  32.951603  0.002999   \n",
       " 2           746588       0.000000          450.0   1.383205  0.002226   \n",
       " 3           799491       0.121816          140.0  47.800123  0.005275   \n",
       " 4           488301       0.029863            5.0   0.034800  0.000078   \n",
       " ..             ...            ...            ...        ...       ...   \n",
       " 937         786393       0.452778          775.0   1.527920  0.001125   \n",
       " 938         842827       0.000000        10000.0   6.004158  0.001423   \n",
       " 939         778113       0.129861          525.0  81.217870  0.002692   \n",
       " 940         709809       0.137500         2000.0  22.420043  0.003456   \n",
       " 941         980439       0.630208         2000.0  75.513667  0.002456   \n",
       " \n",
       "      IMPLIED_VOLA  INPUT_VOLATILITY      PARITY     PREMIUM  \\\n",
       " 0        0.000000              60.0   18.113178  314.515342   \n",
       " 1       49.935913              60.0   26.082707  181.697374   \n",
       " 2        0.000000              34.0   62.267166   65.014737   \n",
       " 3       34.557953              34.5   31.080000   49.405602   \n",
       " 4        0.000000              41.7   56.724043   73.377981   \n",
       " ..            ...               ...         ...         ...   \n",
       " 937     69.585968              44.3   39.421158  152.402532   \n",
       " 938      0.000000              60.0    4.477612  347.247333   \n",
       " 939      0.000000              60.0  123.758440    1.315110   \n",
       " 940    135.361328              60.0   27.964583  189.958196   \n",
       " 941     73.020020              60.0   80.080442   36.163084   \n",
       " \n",
       "      THEORETICAL_PRICE                 VALUE_DATE      VEGA  \n",
       " 0            76.938249  2023-04-14T00:00:00+02:00  0.043240  \n",
       " 1            74.987068  2023-04-14T00:00:00+02:00  0.147927  \n",
       " 2           103.129966  2023-04-14T00:00:00+02:00  0.030651  \n",
       " 3            46.543980  2023-04-14T00:00:00+02:00  0.246013  \n",
       " 4            98.659958  2023-04-14T00:00:00+02:00  0.000949  \n",
       " ..                 ...                        ...       ...  \n",
       " 937          98.195093  2023-04-14T00:00:00+02:00  0.020626  \n",
       " 938          20.468008  2023-04-14T00:00:00+02:00  0.007995  \n",
       " 939         145.506816  2023-04-14T00:00:00+02:00  0.404074  \n",
       " 940          72.933728  2023-04-14T00:00:00+02:00  0.104010  \n",
       " 941         104.268956  2023-04-14T00:00:00+02:00  0.369567  \n",
       " \n",
       " [942 rows x 12 columns]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = len(resultList)\n",
    "\n",
    "instrTD = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(j):\n",
    "    instrTD = instrTD.append(resultList[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = len(resultListPrice)\n",
    "\n",
    "priceTD = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(j):\n",
    "    priceTD = priceTD.append(resultListPrice[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instrTD.to_excel(\"Output_Saturn/instrTD.xlsx\",index=False,na_rep='NA')\n",
    "#priceTD.to_excel(\"Output_Saturn/priceTD.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "idl =instr[['INSTRUMENT_ID','REFERENCE_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add reference ID (EQ) to InstrTD. Keeps only active positions which are equities (REFERNCE_ID)\n",
    "instrTD = instrTD.merge(idl,on='INSTRUMENT_ID',how='inner')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add merge key for later merge\n",
    "\n",
    "instrTD['merge_key_eq'] = instrTD['REFERENCE_ID'].astype(str) + instrTD['VALUE_DATE']\n",
    "instrTD['merge_key_cb'] = instrTD['INSTRUMENT_ID'].astype(str) + instrTD['VALUE_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create merge key id for priceTD\n",
    "priceTD['merge_key_prices'] = priceTD['INSTRUMENT_ID'].astype(str) + priceTD['PRICE_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CB prices with instrTD \n",
    "\n",
    "saturnData_cb = pd.merge(instrTD,priceTD,left_on='merge_key_cb',right_on='merge_key_prices',how='inner')\n",
    "saturnData_cb = saturnData_cb.rename(columns={'PRICE_CLOSE':'PRICE_CB'})\n",
    "saturnData_cb = saturnData_cb.rename(columns={'INSTRUMENT_ID_x':'INSTRUMENT_ID'})\n",
    "\n",
    "del saturnData_cb['INSTRUMENT_ID_y']\n",
    "del saturnData_cb['merge_key_prices']\n",
    "del saturnData_cb['merge_key_cb']\n",
    "del saturnData_cb['PRICE_DATE']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge EQ prices with instrTD \n",
    "\n",
    "saturnData_1 = pd.merge(saturnData_cb,priceTD,how='inner',left_on='merge_key_eq',right_on='merge_key_prices')\n",
    "saturnData_1 = saturnData_1.rename(columns={'PRICE_CLOSE':'PRICE_EQ'})\n",
    "saturnData_1 = saturnData_1.rename(columns={'INSTRUMENT_ID_x':'INSTRUMENT_ID'})\n",
    "saturnData_1 = saturnData_1.rename(columns={'PRICE_CCY_x':'PRICE_CCY'})\n",
    "\n",
    "del saturnData_1['INSTRUMENT_ID_y']\n",
    "del saturnData_1['PRICE_CCY_y']\n",
    "\n",
    "del saturnData_1['merge_key_eq']\n",
    "del saturnData_1['merge_key_prices']\n",
    "del saturnData_1['PRICE_DATE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Dynamic (saturnData_1) and static Data(instr)\n",
    "saturn = pd.merge(saturnData_1,instr,how='outer',on='INSTRUMENT_ID')\n",
    "\n",
    "saturn = saturn.rename(columns={'REFERENCE_ID_x':'REFERENCE_ID'})\n",
    "del saturn['REFERENCE_ID_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert String to Date\n",
    "#saturn_all['VALUE_DATE'] = pd.to_datetime(saturn_all['VALUE_DATE'])\n",
    "#saturn_all['ISSUE_DATE'] = pd.to_datetime(saturn_all['ISSUE_DATE'])\n",
    "\n",
    "#saturn['ISSUE_DATE'] = pd.to_datetime(saturn['ISSUE_DATE'])\n",
    "#saturn['MATURITY_DATE'] = pd.to_datetime(saturn['MATURITY_DATE'])\n",
    "#saturn['NEXT_PUT_DATE'] = pd.to_datetime(saturn['NEXT_PUT_DATE'], errors='coerce') #removes invalid date of 9999\n",
    "#saturn['NEXT_CALL_DATE'] = pd.to_datetime(saturn['NEXT_CALL_DATE'],errors='coerce') #removes invalid date of 9999\n",
    "\n",
    "\n",
    "\n",
    "saturn['IMPLIED_VOLA'] = saturn['IMPLIED_VOLA'].replace(0,np.nan)\n",
    "saturn['IMPLIED_VOLA'] = saturn['IMPLIED_VOLA'].replace('',np.nan)\n",
    "\n",
    "\n",
    "\n",
    "saturn.sort_values(by=['VALUE_DATE'],inplace=True,ascending=False)\n",
    "\n",
    "#rawData = saturn_all\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting string to value\n",
    "\n",
    "# start stop and step variables \n",
    "start, stop, step = 0, 10, 1\n",
    "\n",
    "# Removing string from date\n",
    "\n",
    "saturn['MATURITY_DATE']= saturn['MATURITY_DATE'].str.slice(start, stop, step) \n",
    "saturn['ISSUE_DATE']= saturn['ISSUE_DATE'].str.slice(start, stop, step)\n",
    "saturn['VALUE_DATE']= saturn['VALUE_DATE'].str.slice(start, stop, step) \n",
    "\n",
    "# convert the 'Date' column to datetime format\n",
    "\n",
    "#rawData['MATURITY_DATE'] = rawData['MATURITY_DATE'].astype('datetime64[ns]')\n",
    "saturn[\"MATURITY_DATE\"] = pd.to_datetime(saturn[\"MATURITY_DATE\"]).dt.date\n",
    "saturn[\"ISSUE_DATE\"] = pd.to_datetime(saturn[\"ISSUE_DATE\"]).dt.date\n",
    "saturn[\"VALUE_DATE\"] = pd.to_datetime(saturn[\"VALUE_DATE\"]).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cLEAN prices for units\n",
    "saturn[\"PRICE_CB_CLEAN\"] = np.where(saturn['IS_NOMINAL']=='N',(saturn['PRICE_CB'] - saturn['ACCRUED_VALUE']), saturn['PRICE_CB'])\n",
    "\n",
    "#Converts Unit prices in %\n",
    "#rawData['PRICE_%'] = np.where(rawData['IS_NOMINAL']=='N', (rawData['PRICE_CB'] / rawData['DENOMINATION'] * 100) , rawData['PRICE_CB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(saturn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert retrieved data into table\n",
    "import sqlite3 as sql\n",
    "conn = sql.connect('saturn.db')\n",
    "saturn.to_sql('cb', conn, if_exists='append', index=False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Select * FROM cb WHERE VALUE_DATE>'2022-01-22'\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateStrg = \"'\" + str((Curr - timedelta(days=450)).date()) + \"'\"\n",
    "DateStrgSQL = \"Select * FROM cb WHERE VALUE_DATE>\" + DateStrg\n",
    "DateStrgSQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from SQL for the last 2 years\n",
    "import sqlite3 as sql\n",
    "conn = sql.connect('saturn.db')\n",
    "#saturnDB = pd.read_sql(\"SELECT * FROM cb WHERE VALUE_DATE>'2022-01-01'\", conn)\n",
    "saturnDB = pd.read_sql(DateStrgSQL, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete certain dates\n",
    "\n",
    "#conn = sql.connect('saturn.db')\n",
    "#cur = conn.cursor()\n",
    "#cur.execute(\"DELETE FROM cb WHERE VALUE_DATE>'2022-02-01'\")\n",
    "#conn.commit()\n",
    "#conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-24'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saturnDB['VALUE_DATE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saturnDB.to_excel(\"Output_Saturn/DB.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturn = saturnDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturn = saturn.sort_values(by=['VALUE_DATE'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saturnDB[['VALUE_DATE','DELTA']].to_excel(\"Output_Saturn/date.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def price_regression(instrument):\n",
    "    \n",
    "    #results = ()\n",
    "    #results = pd.DataFrame(columns=['a','b'])\n",
    "    \n",
    "    x = instrument.PARITY\n",
    "    y = instrument.PRICE_CB_CLEAN\n",
    "    \n",
    "    z = np.polyfit(x, y, deg=2) #coeficcient\n",
    "    p = np.poly1d(z) #poly\n",
    "    c = np.polyval(z,x) #slope\n",
    "    \n",
    "    #R2\n",
    "    yhat = p(x)                      # or [p(z) for z in x]\n",
    "    ybar = np.sum(y)/len(y)          # or sum(y)/len(y)\n",
    "    ssreg = np.sum((yhat-ybar)**2)   # or sum([ (yihat - ybar)**2 for yihat in yhat])\n",
    "    sstot = np.sum((y - ybar)**2)    # or sum([ (yi - ybar)**2 for yi in y])\n",
    "    R2 = ssreg / sstot\n",
    "    \n",
    "    #RMSE Root Mean Squared Error\n",
    "    RMSE = np.sqrt(mean_squared_error(y,c))\n",
    "    \n",
    "    \n",
    "    #residual standard error  \n",
    "    #import math\n",
    "    #y_true = np.array(y)\n",
    "    #y_predicted = np.array(c)\n",
    "    #RSS = np.sum(np.square(y_true - y_predicted))\n",
    "    #rse = math.sqrt(RSS / (len(y_true) - 2))\n",
    "    #rse = math.sqrt(RSS / (len(y_true)-1))\n",
    "                    \n",
    "    return c[0], R2, RMSE, z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturn['VALUE_DATE'] = pd.to_datetime(saturn['VALUE_DATE'],format='%Y-%m-%d')\n",
    "saturn['VALUE_DATE'] = saturn['VALUE_DATE'].dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturn['MATURITY_DATE'] = pd.to_datetime(saturn['MATURITY_DATE'],format='%Y-%m-%d')\n",
    "saturn['MATURITY_DATE'] = saturn['MATURITY_DATE'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneYr = (Curr - timedelta(days=365))\n",
    "saturn_1y = saturn[saturn['VALUE_DATE'] > oneYr.date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 4, 18)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saturn_1y['VALUE_DATE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleCB = saturn_1y[saturn_1y['INSTR_LONG_NAME'] == 'Cerence 3% 2025']\n",
    "SingleCB.to_excel(\"Output_Saturn/SingelCB.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-64-4e3d09df7e05>:3: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n"
     ]
    }
   ],
   "source": [
    "#An R2 of 1 indicates that the regression predictions perfectly fit the data.\n",
    "\n",
    "Reg = saturn_1y.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
    "#Reg[['slope', 'R2']] = Reg.apply(g, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg = Reg.to_frame('test')\n",
    "Reg = Reg['test'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTRUMENT_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16810</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>100.169884</td>\n",
       "      <td>2.501334e-16</td>\n",
       "      <td>1.427986e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>1175.795794</td>\n",
       "      <td>0.227364</td>\n",
       "      <td>3.137663e+01</td>\n",
       "      <td>-1.948461e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16922</th>\n",
       "      <td>79.698074</td>\n",
       "      <td>0.615380</td>\n",
       "      <td>2.106578e+00</td>\n",
       "      <td>2.040615e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16923</th>\n",
       "      <td>76.910476</td>\n",
       "      <td>0.276348</td>\n",
       "      <td>2.664047e+00</td>\n",
       "      <td>4.234493e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>110.842737</td>\n",
       "      <td>0.961081</td>\n",
       "      <td>1.623395e+00</td>\n",
       "      <td>7.278176e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023933</th>\n",
       "      <td>101.329387</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>5.679094e-01</td>\n",
       "      <td>-3.485181e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023934</th>\n",
       "      <td>102.235717</td>\n",
       "      <td>0.323902</td>\n",
       "      <td>1.885719e+00</td>\n",
       "      <td>-2.157767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024366</th>\n",
       "      <td>96.838533</td>\n",
       "      <td>0.941916</td>\n",
       "      <td>2.716758e-01</td>\n",
       "      <td>-6.402867e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026112</th>\n",
       "      <td>102.982000</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.842171e-14</td>\n",
       "      <td>5.564564e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026113</th>\n",
       "      <td>107.387000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.773911e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           1             2             3\n",
       "INSTRUMENT_ID                                                     \n",
       "16810             0.200000  100.169884  2.501334e-16  1.427986e-15\n",
       "16846          1175.795794    0.227364  3.137663e+01 -1.948461e-03\n",
       "16922            79.698074    0.615380  2.106578e+00  2.040615e-01\n",
       "16923            76.910476    0.276348  2.664047e+00  4.234493e-01\n",
       "16999           110.842737    0.961081  1.623395e+00  7.278176e-04\n",
       "...                    ...         ...           ...           ...\n",
       "1023933         101.329387    0.347729  5.679094e-01 -3.485181e-02\n",
       "1023934         102.235717    0.323902  1.885719e+00 -2.157767e-01\n",
       "1024366          96.838533    0.941916  2.716758e-01 -6.402867e-02\n",
       "1026112         102.982000         inf  2.842171e-14  5.564564e-03\n",
       "1026113         107.387000         NaN  0.000000e+00  5.773911e-03\n",
       "\n",
       "[1080 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneMthEnd = (Curr - timedelta(days=30))\n",
    "oneMthStart = (Curr - timedelta(days=395))\n",
    "#oneMth.date()\n",
    "saturn_1m = saturn[(saturn['VALUE_DATE'] <= oneMthEnd.date()) & (saturn['VALUE_DATE'] >= oneMthStart.date())]\n",
    "#saturn_1m = (saturn['VALUE_DATE'] >= oneMthStart.date()) & (saturn['VALUE_DATE'] <= oneMthEnd.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SingleCB_1m = saturn_1m[saturn_1m['INSTR_LONG_NAME'] == 'Cerence 3% 2025']\n",
    "#SingleCB_1m.to_excel(\"Output_Saturn/SingelCB_1m.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-69-ff0030a904ef>:1: RankWarning: Polyfit may be poorly conditioned\n",
      "  Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n",
      "<ipython-input-58-2813672645cb>:20: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  R2 = ssreg / sstot\n"
     ]
    }
   ],
   "source": [
    "Reg_1m = saturn_1m.groupby('INSTRUMENT_ID').apply(lambda x: price_regression(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_1m = Reg_1m.to_frame('test')\n",
    "Reg_1m = Reg_1m['test'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Reg_1m.rename(columns={0: \"BINOMINAL_VALUE_1m\", 1: 'R2_Score_1m', 2: 'RMSE_1m', 3: 'z_1m'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reg.rename(columns={0: \"BINOMINAL_VALUE\", 1: 'R2_Score', 2:'RSE' }, inplace=True)\n",
    "Reg.rename(columns={0: \"BINOMINAL_VALUE\", 1: 'R2_Score', 2: 'RMSE', 3: 'z'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BINOMINAL_VALUE', 'R2_Score','RMSE']\n",
    "cols_1m = ['BINOMINAL_VALUE_1m', 'R2_Score_1m','RMSE_1m']\n",
    "Reg[cols] = Reg[cols].round(2)\n",
    "Reg_1m[cols_1m] = Reg_1m[cols_1m].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reg_1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reg.to_excel(\"Output_Saturn/Reg.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastDate = saturn_1y['VALUE_DATE'].max()\n",
    "recentData = saturn_1y[saturn_1y['VALUE_DATE']==lastDate]\n",
    "#recentData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal = pd.merge(recentData,Reg,how='left',on='INSTRUMENT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastDate_1m = saturn_1m['VALUE_DATE'].max()\n",
    "recentData_1m = saturn_1m[saturn_1m['VALUE_DATE']==lastDate_1m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "recentData_1m = pd.merge(recentData_1m,Reg_1m,how='left',on='INSTRUMENT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating EPSILON 1 month ago\n",
    "recentData_1m['BINOMINAL_EPSILON_1m'] = (recentData_1m['BINOMINAL_VALUE_1m'] / recentData_1m['PRICE_CB_CLEAN'] - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergin Holdings\n",
    "\n",
    "#saturnDataFinal = pd.merge(saturnDataFinal,pos,how='left',on='INSTRUMENT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Alpoha\n",
    "saturnDataFinal['BINOMINAL_EPSILON'] = (saturnDataFinal['BINOMINAL_VALUE'] / saturnDataFinal['PRICE_CB_CLEAN'] - 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saturnDataFinal['BINOMINAL_EPSILON_ZSCORE'] = ((saturnDataFinal['BINOMINAL_VALUE'] - saturnDataFinal['PRICE_CB_CLEAN']) / saturnDataFinal['RSE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal = saturnDataFinal.sort_values(by='BINOMINAL_EPSILON', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with EPSILON 1m\n",
    "saturnDataFinal = pd.merge(saturnDataFinal,recentData_1m[['INSTRUMENT_ID','BINOMINAL_VALUE_1m','R2_Score_1m','BINOMINAL_EPSILON_1m','z_1m']],how='left',on='INSTRUMENT_ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with HOlding Data\n",
    "saturnDataFinal = pd.merge(saturnDataFinal,Holdings[['ISIN','HOLDING']],how='left',on='ISIN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal['BINOMINAL_EPSILON_CHANGE_ABS'] = (saturnDataFinal['BINOMINAL_EPSILON'] - saturnDataFinal['BINOMINAL_EPSILON_1m'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal['VALUE_DATE_1M_END'] = oneMthEnd.date()\n",
    "saturnDataFinal['VALUE_DATE_1M_START'] = oneMthStart.date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "saturnDataFinal.to_excel(\"Output_Saturn/EPSILON.xlsx\",index=False,na_rep='NA')\n",
    "saturnDataFinal.to_excel(\"Q:/DAA/Convertible/Research/Polynomial Model/Python/Universe/EPSILON.xlsx\",index=False,na_rep='NA')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "tday = Curr\n",
    "matur = (Curr - timedelta(days=-365))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaturnEPSILONList_Upside = saturnDataFinal.loc[(saturnDataFinal['BINOMINAL_EPSILON']>0.04) & (saturnDataFinal['ISSUE_SIZE_OUT']>149000000) & (saturnDataFinal['R2_Score']>0.7) & (saturnDataFinal['HOLDING'].isnull()) & (saturnDataFinal['z']>-0.1) & (saturnDataFinal['CREDIT_SPREAD']<800) & (saturnDataFinal['MATURITY_DATE']>matur.date())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SaturnEPSILONList_Downside = saturnDataFinal.loc[(saturnDataFinal['BINOMINAL_EPSILON']<-0.06) & (saturnDataFinal['HOLDING']>0) & (saturnDataFinal['R2_Score']>0.7) & (saturnDataFinal['MATURITY_DATE']>matur.date())]\n",
    "SaturnEPSILONList_Downside = saturnDataFinal.loc[(saturnDataFinal['BINOMINAL_EPSILON']<-0.01) & (saturnDataFinal['HOLDING']>0) & (saturnDataFinal['R2_Score']>0.5) & (saturnDataFinal['PARITY']>50.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaturnEPSILONList_Upside.to_excel(\"Q:/DAA/Convertible/Research/Polynomial Model/Python/Top/EPSILONShortlist_Upside.xlsx\",index=False,na_rep='NA')\n",
    "SaturnEPSILONList_Upside.to_excel(\"Output_Saturn//Regression/Upside/EPSILONShortlist_Upside.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaturnEPSILONList_Downside.to_excel(\"Q:/DAA/Convertible/Research/Polynomial Model/Python/Flop/EPSILONShortlist_Downside.xlsx\",index=False,na_rep='NA')\n",
    "SaturnEPSILONList_Downside.to_excel(\"Output_Saturn//Regression/Downside/EPSILONShortlist_Downside.xlsx\",index=False,na_rep='NA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaturnConcave = saturnDataFinal.loc[(saturnDataFinal['CREDIT_SPREAD']<750) & (saturnDataFinal['PRICE_CB_CLEAN']<140) & (saturnDataFinal['PRICE_CB_CLEAN']<140) & (saturnDataFinal['z']<0) & (saturnDataFinal['R2_Score']>0.7) & (saturnDataFinal['MATURITY_DATE']>matur.date())]\n",
    "SaturnConcave = SaturnConcave.sort_values(by='z', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaturnConcave.to_excel(\"Q:/DAA/Convertible/Research/Polynomial Model/Python/Concave/Concave.xlsx\",index=False,na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######END#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
